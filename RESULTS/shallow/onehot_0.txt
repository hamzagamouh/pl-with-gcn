Using backend: pytorch
HELLO !
CUDA is available !!
BEGIN TRAINING 
Embedding :  onehot
CV Fold : fold_0_
Layers :  [21, 32, 64, 128, 2]
Dropout rate :  0
Training for 1000 Epochs 
Batch size :  32
In epoch 0, loss: 0.683, train mcc : 0.085 , val mcc : 0.117
In epoch 50, loss: 0.649, train mcc : 0.170 , val mcc : 0.136
In epoch 100, loss: 0.612, train mcc : 0.195 , val mcc : 0.128
In epoch 150, loss: 0.629, train mcc : 0.210 , val mcc : 0.125
In epoch 200, loss: 0.605, train mcc : 0.220 , val mcc : 0.113
In epoch 250, loss: 0.582, train mcc : 0.227 , val mcc : 0.115
In epoch 300, loss: 0.565, train mcc : 0.232 , val mcc : 0.117
In epoch 350, loss: 0.631, train mcc : 0.239 , val mcc : 0.118
In epoch 400, loss: 0.526, train mcc : 0.246 , val mcc : 0.128
In epoch 450, loss: 0.520, train mcc : 0.247 , val mcc : 0.135
In epoch 500, loss: 0.532, train mcc : 0.253 , val mcc : 0.121
In epoch 550, loss: 0.559, train mcc : 0.255 , val mcc : 0.126
In epoch 600, loss: 0.542, train mcc : 0.260 , val mcc : 0.126
In epoch 650, loss: 0.513, train mcc : 0.259 , val mcc : 0.128
In epoch 700, loss: 0.586, train mcc : 0.266 , val mcc : 0.128
In epoch 750, loss: 0.542, train mcc : 0.266 , val mcc : 0.126
In epoch 800, loss: 0.604, train mcc : 0.266 , val mcc : 0.129
In epoch 850, loss: 0.533, train mcc : 0.269 , val mcc : 0.120
In epoch 900, loss: 0.612, train mcc : 0.272 , val mcc : 0.126
In epoch 950, loss: 0.553, train mcc : 0.274 , val mcc : 0.134
In epoch 1000, loss: 0.579, train mcc : 0.277 , val mcc : 0.126
