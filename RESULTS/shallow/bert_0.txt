Using backend: pytorch
HELLO !
CUDA is available !!
BEGIN TRAINING 
Embedding :  bert
CV Fold : fold_0_
Layers :  [1024, 32, 64, 128, 2]
Dropout rate :  0
Training for 1000 Epochs 
Batch size :  32
In epoch 0, loss: 0.655, train mcc : 0.106 , val mcc : 0.119
In epoch 50, loss: 0.631, train mcc : 0.205 , val mcc : 0.161
In epoch 100, loss: 0.577, train mcc : 0.224 , val mcc : 0.161
In epoch 150, loss: 0.570, train mcc : 0.232 , val mcc : 0.169
In epoch 200, loss: 0.592, train mcc : 0.241 , val mcc : 0.155
In epoch 250, loss: 0.580, train mcc : 0.246 , val mcc : 0.168
In epoch 300, loss: 0.558, train mcc : 0.248 , val mcc : 0.158
In epoch 350, loss: 0.587, train mcc : 0.253 , val mcc : 0.152
In epoch 400, loss: 0.603, train mcc : 0.255 , val mcc : 0.178
In epoch 450, loss: 0.573, train mcc : 0.260 , val mcc : 0.177
In epoch 500, loss: 0.580, train mcc : 0.263 , val mcc : 0.162
In epoch 550, loss: 0.569, train mcc : 0.264 , val mcc : 0.170
In epoch 600, loss: 0.585, train mcc : 0.269 , val mcc : 0.172
In epoch 650, loss: 0.569, train mcc : 0.271 , val mcc : 0.157
In epoch 700, loss: 0.594, train mcc : 0.271 , val mcc : 0.171
In epoch 750, loss: 0.581, train mcc : 0.274 , val mcc : 0.167
In epoch 800, loss: 0.533, train mcc : 0.275 , val mcc : 0.165
In epoch 850, loss: 0.580, train mcc : 0.273 , val mcc : 0.164
In epoch 900, loss: 0.570, train mcc : 0.279 , val mcc : 0.171
In epoch 950, loss: 0.593, train mcc : 0.283 , val mcc : 0.166
In epoch 1000, loss: 0.620, train mcc : 0.275 , val mcc : 0.168
