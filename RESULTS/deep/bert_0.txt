Using backend: pytorch
HELLO !
CUDA is available !!
BEGIN TRAINING 
Embedding :  bert
CV Fold : fold_0_
Layers :  [1024, 512, 512, 512, 512, 512, 512, 2]
Dropout rate :  0
Training for 1000 Epochs 
Batch size :  32
In epoch 0, loss: 0.594, train mcc : 0.127 , val mcc : 0.101
In epoch 50, loss: 0.545, train mcc : 0.341 , val mcc : 0.159
In epoch 100, loss: 0.431, train mcc : 0.414 , val mcc : 0.156
In epoch 150, loss: 0.482, train mcc : 0.447 , val mcc : 0.169
In epoch 200, loss: 0.458, train mcc : 0.482 , val mcc : 0.172
In epoch 250, loss: 0.445, train mcc : 0.496 , val mcc : 0.150
In epoch 300, loss: 0.456, train mcc : 0.514 , val mcc : 0.160
In epoch 350, loss: 0.452, train mcc : 0.516 , val mcc : 0.160
In epoch 400, loss: 0.418, train mcc : 0.526 , val mcc : 0.158
In epoch 450, loss: 0.409, train mcc : 0.540 , val mcc : 0.157
In epoch 500, loss: 0.447, train mcc : 0.548 , val mcc : 0.153
In epoch 550, loss: 0.479, train mcc : 0.552 , val mcc : 0.150
In epoch 600, loss: 0.381, train mcc : 0.562 , val mcc : 0.148
In epoch 650, loss: 0.392, train mcc : 0.564 , val mcc : 0.153
In epoch 700, loss: 0.421, train mcc : 0.571 , val mcc : 0.143
In epoch 750, loss: 0.408, train mcc : 0.569 , val mcc : 0.157
In epoch 800, loss: 0.403, train mcc : 0.578 , val mcc : 0.158
In epoch 850, loss: 0.401, train mcc : 0.581 , val mcc : 0.153
In epoch 900, loss: 0.393, train mcc : 0.583 , val mcc : 0.149
In epoch 950, loss: 0.418, train mcc : 0.597 , val mcc : 0.153
In epoch 1000, loss: 0.408, train mcc : 0.587 , val mcc : 0.157
