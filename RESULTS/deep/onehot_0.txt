Using backend: pytorch
HELLO !
CUDA is available !!
BEGIN TRAINING 
Embedding :  onehot
CV Fold : fold_0_
Layers :  [21, 512, 512, 512, 512, 512, 512, 2]
Dropout rate :  0
Training for 1000 Epochs 
Batch size :  32
In epoch 0, loss: 0.670, train mcc : 0.129 , val mcc : 0.120
In epoch 50, loss: 0.469, train mcc : 0.420 , val mcc : 0.141
In epoch 100, loss: 0.459, train mcc : 0.491 , val mcc : 0.156
In epoch 150, loss: 0.427, train mcc : 0.517 , val mcc : 0.152
In epoch 200, loss: 0.410, train mcc : 0.536 , val mcc : 0.152
In epoch 250, loss: 0.413, train mcc : 0.552 , val mcc : 0.148
In epoch 300, loss: 0.383, train mcc : 0.561 , val mcc : 0.155
In epoch 350, loss: 0.382, train mcc : 0.576 , val mcc : 0.153
In epoch 400, loss: 0.401, train mcc : 0.587 , val mcc : 0.162
In epoch 450, loss: 0.397, train mcc : 0.595 , val mcc : 0.161
In epoch 500, loss: 0.424, train mcc : 0.600 , val mcc : 0.159
In epoch 550, loss: 0.398, train mcc : 0.604 , val mcc : 0.147
In epoch 600, loss: 0.410, train mcc : 0.614 , val mcc : 0.146
In epoch 650, loss: 0.403, train mcc : 0.611 , val mcc : 0.151
In epoch 700, loss: 0.382, train mcc : 0.621 , val mcc : 0.159
In epoch 750, loss: 0.406, train mcc : 0.623 , val mcc : 0.151
In epoch 800, loss: 0.392, train mcc : 0.625 , val mcc : 0.153
In epoch 850, loss: 0.386, train mcc : 0.628 , val mcc : 0.147
In epoch 900, loss: 0.363, train mcc : 0.629 , val mcc : 0.150
In epoch 950, loss: 0.398, train mcc : 0.627 , val mcc : 0.147
In epoch 1000, loss: 0.395, train mcc : 0.624 , val mcc : 0.157
